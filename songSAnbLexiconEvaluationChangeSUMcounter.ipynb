{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import glob\n",
    "import re\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "port = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataset file lists, 4 total, one for each emotion\n",
    "\n",
    "# Train Data Ingestion\n",
    "happy_filelist = glob.glob('./data/Happy/Train/happy*.txt')\n",
    "angry_filelist = glob.glob('./data/Angry/Train/angry*.txt')\n",
    "relaxed_filelist = glob.glob('./data/Relaxed/Train/relaxed*.txt')\n",
    "sad_filelist = glob.glob('./data/Sad/Train/sad*.txt')\n",
    "\n",
    "# Test Data Ingestion\n",
    "happy_filelist2 = glob.glob('./data/Happy/Test/happy*.txt')\n",
    "angry_filelist2 = glob.glob('./data/Angry/Test/angry*.txt')\n",
    "relaxed_filelist2 = glob.glob('./data/Relaxed/Test/relaxed*.txt')\n",
    "sad_filelist2 = glob.glob('./data/Sad/Test/sad*.txt')\n",
    "\n",
    "# Combine Train and Test Data For the Lexicon-Based Analysis\n",
    "happy_filelist = happy_filelist + happy_filelist2\n",
    "angry_filelist = angry_filelist + angry_filelist2\n",
    "relaxed_filelist = relaxed_filelist + relaxed_filelist2\n",
    "sad_filelist = sad_filelist + sad_filelist2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read() function returns:\n",
    "# lyrics(text tokenized, and lowercased without stopwords per song) and\n",
    "# all_words(the lyrics output of all the songs as one list)\n",
    "# based on the input of a file list and emotion tag\n",
    "\n",
    "def read(filelist, tag):\n",
    "    lyrics = []\n",
    "    all_words = []\n",
    "    \n",
    "    for f in filelist:\n",
    "        try:\n",
    "            with open(f,'r') as file:\n",
    "                song = file.read()\n",
    "                file.close()\n",
    "                #added\n",
    "                #song = song.decode(\"utf-8-sig\")\n",
    "                song = re.sub(r\"(\\\\n|\\\\u....|\\t)\", \"\", song)\n",
    "                song = re.sub(r\"(\\[\\d\\d:\\d\\d\\.\\d\\d\\])\",\"\",song)\n",
    "                song = song.lower()\n",
    "                #song = nltk.word_tokenize(song)\n",
    "                song = nltk.word_tokenize(song.translate(str.maketrans('','',string.punctuation)))\n",
    "                song = [w for w in song if not w in string.punctuation]\n",
    "                song = [w for w in song if not w in stop_words]\n",
    "                song = [w for w in song if w != \"'\"]\n",
    "                #song = [w for w in song if not \"\\ufeff\" in w]\n",
    "                #song = [w for w in song if w != \"'\"]\n",
    "                song_tag = (song, tag)\n",
    "                lyrics.append(song_tag)\n",
    "                \n",
    "                for word in song:\n",
    "                    all_words.append(word)\n",
    "        except:\n",
    "            break\n",
    "    return lyrics, all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function finds the features for a song\n",
    "\n",
    "def find_features(song):\n",
    "    words = set(song)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create lyrics list for the 4 emotions seperately, \n",
    "# the entire lyric database, and all_words(a single list of all lyric tokens)\n",
    "\n",
    "happy_lyrics, happy_words = read(happy_filelist, 'happy')\n",
    "angry_lyrics, angry_words = read(angry_filelist, 'angry')\n",
    "relaxed_lyrics, relaxed_words = read(relaxed_filelist, 'relaxed')\n",
    "sad_lyrics, sad_words = read(sad_filelist, 'sad')\n",
    "\n",
    "data = happy_lyrics + angry_lyrics + relaxed_lyrics + sad_lyrics\n",
    "all_words = happy_words + angry_words + relaxed_words + sad_words\n",
    "\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "word_features = list(all_words.keys())[:100] #i changed this to 25 from 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier accuracy percent: 41.23711340206185\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(data)\n",
    "\n",
    "featuresets = [(find_features(song), tag) for (song, tag) in data]\n",
    "\n",
    "train_set = featuresets[:680]\n",
    "test_set = featuresets[681:]\n",
    "\n",
    "model = nltk.NaiveBayesClassifier.train(train_set)\n",
    "                                    \n",
    "print(\"Classifier accuracy percent:\",(nltk.classify.accuracy(model, test_set))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#                              #\n",
    "#                              #\n",
    "#         Lexicon-Based        #\n",
    "#      Sentiment Analysis      #\n",
    "#                              #\n",
    "#                              #\n",
    "\n",
    "\n",
    "# Classifies the emotion of song lyrics based on the similarity of lyrics\n",
    "# and that class's lexicon.  The lexicon is created with the seed word of \n",
    "# the class and is increased in size with synonyms.  Each word in a given\n",
    "# song lyric is compared to each emotion synonym in the class and the sum\n",
    "# is taken.  This sum of emotion similarity is calculated for all 4 emotions\n",
    "# for each test data song.  The maximum of the 4 is chosen as the class\n",
    "# label for that song. Uses wordnet to build the lexicons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# wordnet\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find synonyms and antonyms of the four emotions (in bag of words format)\n",
    "\n",
    "# Relaxed\n",
    "synonymsR = []\n",
    "antonymsR = []\n",
    "\n",
    "for syn in wn.synsets(\"relaxed\"):\n",
    "    for l in syn.lemmas():\n",
    "        synonymsR.append(l.name())\n",
    "        if l.antonyms():\n",
    "            antonymsR.append(l.antonyms()[0].name())\n",
    "\n",
    "#print(set(synonymsR))\n",
    "#print(set(antonymsR))\n",
    "\n",
    "\n",
    "# Happy\n",
    "synonymsH = []\n",
    "antonymsH = []\n",
    "\n",
    "for syn in wn.synsets(\"happy\"):\n",
    "    for l in syn.lemmas():\n",
    "        synonymsH.append(l.name())\n",
    "        if l.antonyms():\n",
    "            antonymsH.append(l.antonyms()[0].name())\n",
    "\n",
    "\n",
    "# Happy: adding \"pleasant\" to increase the lexicon\n",
    "for syn in wn.synsets(\"pleasant\"):\n",
    "    for l in syn.lemmas():\n",
    "        synonymsH.append(l.name())\n",
    "\n",
    "# Happy: adding \"laugh\" to increase the lexicon size\n",
    "for syn in wn.synsets(\"laugh\"):\n",
    "    for l in syn.lemmas():\n",
    "        synonymsH.append(l.name())\n",
    "        \n",
    "# Sad\n",
    "synonymsS = []\n",
    "antonymsS = []\n",
    "\n",
    "for syn in wn.synsets(\"sad\"):\n",
    "    for l in syn.lemmas():\n",
    "        synonymsS.append(l.name())\n",
    "        if l.antonyms():\n",
    "            antonymsS.append(l.antonyms()[0].name())\n",
    "\n",
    "#print(set(synonymsS))\n",
    "#print(set(antonymsS))\n",
    "\n",
    "\n",
    "# Angry\n",
    "synonymsA = []\n",
    "antonymsA = []\n",
    "\n",
    "for syn in wn.synsets(\"angry\"):\n",
    "    for l in syn.lemmas():\n",
    "        synonymsA.append(l.name())\n",
    "        if l.antonyms():\n",
    "            antonymsA.append(l.antonyms()[0].name())\n",
    "\n",
    "# Angry: adding \"hate\" to increase the lexicon\n",
    "for syn in wn.synsets(\"hate\"):\n",
    "    for l in syn.lemmas():\n",
    "        synonymsA.append(l.name())\n",
    "\n",
    "#print(set(synonymsA))\n",
    "#print(set(antonymsA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gag', 'express_mirth', 'jest', 'well-chosen', 'glad', 'laughter', 'felicitous', 'jape', 'happy', 'laugh', 'express_joy', 'joke', 'pleasant']\n",
      "['slack_up', 'unstrain', 'unwind', 'slack', 'loosen_up', 'slacken', 'unlax', 'relax', 'unbend', 'loosen', 'loose', 'relaxed', 'slow_down', 'make_relaxed', 'decompress']\n",
      "['lamentable', 'pitiful', 'sorry', 'distressing', 'sad', 'deplorable']\n",
      "['furious', 'hatred', 'angry', 'wild', 'hate', 'tempestuous', 'detest', 'raging']\n"
     ]
    }
   ],
   "source": [
    "#synonymsA[0] # gives the 1st element in the list\n",
    "\n",
    "# Get unique values only\n",
    "synonymsA = set(synonymsA) \n",
    "synonymsR = set(synonymsR)\n",
    "synonymsH = set(synonymsH)\n",
    "synonymsS = set(synonymsS)\n",
    "\n",
    "# Convert sets back to lists\n",
    "synonymsA = list(synonymsA) \n",
    "synonymsR = list(synonymsR)\n",
    "synonymsH = list(synonymsH)\n",
    "synonymsS = list(synonymsS)\n",
    "\n",
    "#print(synonymsH)\n",
    "#j = len(synonymsH) # need to loop through synonyms from 1 to j for Angry\n",
    "#print(j)\n",
    "\n",
    "#synonymsH[0]\n",
    "print(synonymsH)\n",
    "print(synonymsR)\n",
    "print(synonymsS)\n",
    "print(synonymsA)\n",
    "\n",
    "#sum = 2\n",
    "#sum/len(synonymsH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happy'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#                              #\n",
    "#                              #\n",
    "#        ENTER TEST DATA       #\n",
    "#                              #\n",
    "#                              #\n",
    "\n",
    "#testdata = test_setRelaxed\n",
    "#testdata = alldocs\n",
    "testdata = data\n",
    "testdata[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a dataframe to store the test data's emotions similarity sum \n",
    "# scores for each of the four emotions. Rows = songs and 4 cols = emotion, one is for max class label \n",
    "# similarity sums. df#rows = #rows in the test data.\n",
    "import pandas, numpy\n",
    "\n",
    "#currently, the test input is test_setHappy\n",
    "#df1 = pandas.DataFrame(0, index=np.arange(len(test_setHappy)), columns = ['Happy', 'Relaxed', 'Sad', 'Angry', 'MaxClass', 'ActualClass'])\n",
    "df1 = pandas.DataFrame(index=np.arange(len(testdata)), columns = ['happy', 'relaxed', 'sad', 'angry', 'MaxClass', 'ActualClass'])\n",
    "#df1.iloc[0,0] = 2  #19 rows: 0-18, cols: 0-3, 0=happy 1=relaxed 2=sad 3=angry, 4=predictedclass 5=actualclass\n",
    "#df1\n",
    "\n",
    "# to find the class of the song, we take the max of the row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is the class label: testdata[songIndex][1]\n",
    "# need to add this to the matrix for each index of testdata[index][1] at df1[index, 5]\n",
    "  \n",
    "# add \"actual\" class labels to the matrix for each song\n",
    "for songIndex in range(len(testdata)):\n",
    "    df1.iloc[songIndex, 5] = testdata[songIndex][1]\n",
    "\n",
    "#df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compare each lyric word in a song to every word in the Synonym list \n",
    "#  for each emotion\n",
    "\n",
    "# HAPPY COLUMN CALCULATIONS\n",
    "\n",
    "#this loop will assess every song\n",
    "songind = 0  #j will be used as the row value for inputting sim sums into the df\n",
    "\n",
    "x = len(testdata)  #number of items in the test set\n",
    "\n",
    "#loop through every song:\n",
    "for i in range(x):\n",
    "    #songind+=1\n",
    "    firstsong = testdata[songind][0]\n",
    "\n",
    "    sum = 0  # initialize the sum value, per song, per emotion. If the simw1w2 is not 0, i.e. not \"None\", we want to keep track of it\n",
    "\n",
    "    for w in firstsong:\n",
    "        #if w1 is not null, then we do the rest of this cell....\n",
    "        if wn.synsets(w):\n",
    "            w1 = wn.synsets(w)[0]\n",
    "            #print('w1')\n",
    "            #print(w1)\n",
    "            # For each of the synonyms of Happy, if similarity b/t w1 and w2 is \n",
    "            for j in range(len(synonymsH)):\n",
    "                w2 = synonymsH[j]\n",
    "                w2 = wn.synsets(w2)[0]\n",
    "                #print('w2')\n",
    "                #print(w2)\n",
    "                w1w2sim = w1.wup_similarity(w2)\n",
    "                #print(w1w2sim)\n",
    "                if w1w2sim != None:\n",
    "                    if w1w2sim > 0.7:\n",
    "                        sum += 1\n",
    "                        sum = sum / len(synonymsH) #normalize the sum by dividing by the number of synonymns\n",
    "                        sum = sum / len(firstsong) #normalize the sum by dividing by the number of words in the song\n",
    "                        #print('sum')\n",
    "                        #print(sum)   # this is the sum for the first song's happy similarities\n",
    "    df1.iloc[songind,0] = sum\n",
    "    songind += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RELAXED CALCULATIONS\n",
    "\n",
    "#this loop will assess every song\n",
    "songind = 0  #j will be used as the row value for inputting sim sums into the df\n",
    "\n",
    "for i in range(x):\n",
    "    #songind+=1\n",
    "    firstsong = testdata[songind][0]\n",
    "\n",
    "    sum = 0  # initialize the sum value, per song, per emotion. If the simw1w2 is not 0, i.e. not \"None\", we want to keep track of it\n",
    "\n",
    "    for w in firstsong:\n",
    "        #if w1 is not null, then we do the rest of this cell....\n",
    "        if wn.synsets(w):\n",
    "            w1 = wn.synsets(w)[0]\n",
    "            #print('w1')\n",
    "            #print(w1)\n",
    "            # For each of the synonyms of Relaxed, if similarity b/t w1 and w2 is \n",
    "            for j in range(len(synonymsR)):\n",
    "                w2 = synonymsR[j]\n",
    "                w2 = wn.synsets(w2)[0]\n",
    "                #print('w2')\n",
    "                #print(w2)\n",
    "                w1w2sim = w1.wup_similarity(w2)\n",
    "                #print(w1w2sim)\n",
    "                if w1w2sim != None:\n",
    "                    if w1w2sim > 0.7:\n",
    "                        sum += 1\n",
    "                        sum = sum / len(synonymsR) #normalize the sum by dividing by the number of synonymns\n",
    "                        sum = sum / len(firstsong) #normalize the sum by dividing by the number of words in the song\n",
    "                        #print('sum')\n",
    "                        #print(sum)   # this is the sum for the first song's Relaxed similarities\n",
    "    df1.iloc[songind,1] = sum\n",
    "    songind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SAD CALCULATIONS\n",
    "\n",
    "#this loop will assess every song\n",
    "songind = 0  #j will be used as the row value for inputting sim sums into the df\n",
    "\n",
    "for i in range(x):\n",
    "    #songind+=1\n",
    "    firstsong = testdata[songind][0]\n",
    "\n",
    "    sum = 0  # initialize the sum value, per song, per emotion. If the simw1w2 is not 0, i.e. not \"None\", we want to keep track of it\n",
    "\n",
    "    for w in firstsong:\n",
    "        #if w1 is not null, then we do the rest of this cell....\n",
    "        if wn.synsets(w):\n",
    "            w1 = wn.synsets(w)[0]\n",
    "            #print('w1')\n",
    "            #print(w1)\n",
    "            # For each of the synonyms of Sad, if similarity b/t w1 and w2 is \n",
    "            for j in range(len(synonymsS)):\n",
    "                w2 = synonymsS[j]\n",
    "                w2 = wn.synsets(w2)[0]\n",
    "                #print('w2')\n",
    "                #print(w2)\n",
    "                w1w2sim = w1.wup_similarity(w2)\n",
    "                #print(w1w2sim)\n",
    "                if w1w2sim != None:\n",
    "                    if w1w2sim > 0.7:\n",
    "                        sum += 1\n",
    "                        sum = sum / len(synonymsS) #normalize the sum by dividing by the number of synonymns\n",
    "                        sum = sum / len(firstsong) #normalize the sum by dividing by the number of words in the song\n",
    "                        #print('sum')\n",
    "                        #print(sum)   # this is the sum for the first song's Sad similarities\n",
    "    df1.iloc[songind,2] = sum\n",
    "    songind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ANGRY CALCULATIONS\n",
    "\n",
    "#this loop will assess every song\n",
    "songind = 0  #j will be used as the row value for inputting sim sums into the df\n",
    "\n",
    "x = len(testdata)\n",
    "for i in range(x):\n",
    "    #songind+=1\n",
    "    firstsong = testdata[songind][0]\n",
    "\n",
    "    sum = 0  # initialize the sum value, per song, per emotion. If the simw1w2 is not 0, i.e. not \"None\", we want to keep track of it\n",
    "\n",
    "    for w in firstsong:\n",
    "        #if w1 is not null, then we do the rest of this cell....\n",
    "        if wn.synsets(w):\n",
    "            w1 = wn.synsets(w)[0]\n",
    "            #print('w1')\n",
    "            #print(w1)\n",
    "            # For each of the synonyms of Angry, if similarity b/t w1 and w2 is \n",
    "            for j in range(len(synonymsA)):\n",
    "                w2 = synonymsA[j]\n",
    "                w2 = wn.synsets(w2)[0]\n",
    "                #print('w2')\n",
    "                #print(w2)\n",
    "                w1w2sim = w1.wup_similarity(w2)\n",
    "                #print(w1w2sim)\n",
    "                if w1w2sim != None:\n",
    "                    if w1w2sim > 0.7:\n",
    "                        sum += 1\n",
    "                        sum = sum / len(synonymsA) #normalize the sum by dividing by the number of synonymns\n",
    "                        sum = sum / len(firstsong) #normalize the sum by dividing by the number of words in the song\n",
    "                        #print('sum')\n",
    "                        #print(sum)   # this is the sum for the first song's Angry similarities\n",
    "    df1.iloc[songind,3] = sum\n",
    "    songind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find the max similarity value of each row and assign the class of that\n",
    "# value as the Maximum Class Output class label\n",
    "\n",
    "indx = 0\n",
    "\n",
    "for i in range(x):\n",
    "    #print(df1.iloc[indx].argmax())\n",
    "    df1.iloc[indx, 4] = df1.iloc[indx, 0:3].argmax()\n",
    "    #df1.iloc[indx, 4] = df1.iloc[indx].argmax()\n",
    "    \n",
    "    indx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>happy</th>\n",
       "      <th>relaxed</th>\n",
       "      <th>sad</th>\n",
       "      <th>angry</th>\n",
       "      <th>MaxClass</th>\n",
       "      <th>ActualClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000571102</td>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000806452</td>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000498008</td>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000846024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00137552</td>\n",
       "      <td>happy</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000460617</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000749064</td>\n",
       "      <td>happy</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000919118</td>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000740192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00120337</td>\n",
       "      <td>happy</td>\n",
       "      <td>relaxed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000474834</td>\n",
       "      <td>0.000411523</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000772201</td>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000484027</td>\n",
       "      <td>0.000419463</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000786782</td>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00186915</td>\n",
       "      <td>happy</td>\n",
       "      <td>relaxed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.00135135</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0021978</td>\n",
       "      <td>happy</td>\n",
       "      <td>relaxed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.00160514</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00261097</td>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000405022</td>\n",
       "      <td>0.000350877</td>\n",
       "      <td>0.000877193</td>\n",
       "      <td>0.000658328</td>\n",
       "      <td>sad</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00198807</td>\n",
       "      <td>happy</td>\n",
       "      <td>relaxed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000565931</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000919963</td>\n",
       "      <td>happy</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000390625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000634518</td>\n",
       "      <td>happy</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000881057</td>\n",
       "      <td>happy</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000341997</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000555864</td>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00104275</td>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000235571</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000441891</td>\n",
       "      <td>relaxed</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000569801</td>\n",
       "      <td>0.000493827</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000926784</td>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000568505</td>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000735835</td>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>happy</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00202019</td>\n",
       "      <td>happy</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00121507</td>\n",
       "      <td>happy</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0020202</td>\n",
       "      <td>happy</td>\n",
       "      <td>relaxed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000530786</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000862813</td>\n",
       "      <td>happy</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0014556</td>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000225225</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000422476</td>\n",
       "      <td>relaxed</td>\n",
       "      <td>relaxed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>0.000726216</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00156495</td>\n",
       "      <td>happy</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>0.000596659</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000969932</td>\n",
       "      <td>happy</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00162602</td>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>0.000466418</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00075815</td>\n",
       "      <td>happy</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00139082</td>\n",
       "      <td>happy</td>\n",
       "      <td>relaxed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00147275</td>\n",
       "      <td>happy</td>\n",
       "      <td>relaxed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00103413</td>\n",
       "      <td>happy</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000619195</td>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00198807</td>\n",
       "      <td>happy</td>\n",
       "      <td>relaxed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>0.000138619</td>\n",
       "      <td>0.000120135</td>\n",
       "      <td>0.0003003</td>\n",
       "      <td>0.000225276</td>\n",
       "      <td>sad</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>0.000615763</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>happy</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00173913</td>\n",
       "      <td>happy</td>\n",
       "      <td>relaxed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>0.00160513</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00261097</td>\n",
       "      <td>happy</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000631712</td>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000610128</td>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>0.000185839</td>\n",
       "      <td>0.000161031</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000302024</td>\n",
       "      <td>happy</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>0.000361272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>happy</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000665336</td>\n",
       "      <td>happy</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>0.000630915</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00102564</td>\n",
       "      <td>happy</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>0.000874126</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00142248</td>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>0.000167983</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>happy</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>0.000472143</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00076746</td>\n",
       "      <td>happy</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>0.00142653</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00232019</td>\n",
       "      <td>happy</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0008285</td>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>0.000874891</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00142248</td>\n",
       "      <td>happy</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>happy</td>\n",
       "      <td>relaxed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000616143</td>\n",
       "      <td>happy</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>778 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           happy      relaxed          sad        angry MaxClass ActualClass\n",
       "0              0            0            0  0.000571102    happy       happy\n",
       "1              0            0            0  0.000806452    happy       happy\n",
       "2              0            0            0  0.000498008    happy       happy\n",
       "3    0.000846024            0            0   0.00137552    happy         sad\n",
       "4    0.000460617            0            0  0.000749064    happy         sad\n",
       "5              0            0            0  0.000919118    happy       happy\n",
       "6    0.000740192            0            0   0.00120337    happy     relaxed\n",
       "7    0.000474834  0.000411523            0  0.000772201    happy       happy\n",
       "8    0.000484027  0.000419463            0  0.000786782    happy       happy\n",
       "9              0            0            0   0.00186915    happy     relaxed\n",
       "10    0.00135135            0            0    0.0021978    happy     relaxed\n",
       "11    0.00160514            0            0   0.00261097    happy       happy\n",
       "12   0.000405022  0.000350877  0.000877193  0.000658328      sad       happy\n",
       "13             0            0            0   0.00198807    happy     relaxed\n",
       "14   0.000565931            0            0  0.000919963    happy         sad\n",
       "15   0.000390625            0            0  0.000634518    happy       angry\n",
       "16             0            0            0  0.000881057    happy         sad\n",
       "17   0.000341997            0            0  0.000555864    happy       happy\n",
       "18             0            0            0   0.00104275    happy       happy\n",
       "19             0  0.000235571            0  0.000441891  relaxed       happy\n",
       "20   0.000569801  0.000493827            0  0.000926784    happy       happy\n",
       "21             0            0            0  0.000568505    happy       happy\n",
       "22             0            0            0  0.000735835    happy       happy\n",
       "23             0            0            0            0    happy       angry\n",
       "24             0            0            0   0.00202019    happy         sad\n",
       "25             0            0            0   0.00121507    happy       angry\n",
       "26             0            0            0    0.0020202    happy     relaxed\n",
       "27   0.000530786            0            0  0.000862813    happy         sad\n",
       "28             0            0            0    0.0014556    happy       happy\n",
       "29             0  0.000225225            0  0.000422476  relaxed     relaxed\n",
       "..           ...          ...          ...          ...      ...         ...\n",
       "748  0.000726216            0            0            0    happy       happy\n",
       "749            0            0            0   0.00156495    happy         sad\n",
       "750  0.000596659            0            0  0.000969932    happy         sad\n",
       "751            0            0            0   0.00162602    happy       happy\n",
       "752  0.000466418            0            0   0.00075815    happy         sad\n",
       "753            0            0            0   0.00139082    happy     relaxed\n",
       "754            0            0            0            0    happy       happy\n",
       "755            0            0            0   0.00147275    happy     relaxed\n",
       "756            0            0            0   0.00103413    happy       angry\n",
       "757            0            0            0  0.000619195    happy       happy\n",
       "758            0            0            0   0.00198807    happy     relaxed\n",
       "759  0.000138619  0.000120135    0.0003003  0.000225276      sad       angry\n",
       "760  0.000615763            0            0     0.001001    happy         sad\n",
       "761            0            0            0   0.00173913    happy     relaxed\n",
       "762   0.00160513            0            0   0.00261097    happy         sad\n",
       "763            0            0            0  0.000631712    happy       happy\n",
       "764            0            0            0  0.000610128    happy       happy\n",
       "765  0.000185839  0.000161031            0  0.000302024    happy       angry\n",
       "766  0.000361272            0            0            0    happy         sad\n",
       "767            0            0            0  0.000665336    happy         sad\n",
       "768  0.000630915            0            0   0.00102564    happy       angry\n",
       "769  0.000874126            0            0   0.00142248    happy       happy\n",
       "770  0.000167983            0            0     0.000273    happy       angry\n",
       "771  0.000472143            0            0   0.00076746    happy         sad\n",
       "772   0.00142653            0            0   0.00232019    happy       angry\n",
       "773            0            0            0            0    happy       happy\n",
       "774            0            0            0    0.0008285    happy       happy\n",
       "775  0.000874891            0            0   0.00142248    happy         sad\n",
       "776            0            0            0            0    happy     relaxed\n",
       "777            0            0            0  0.000616143    happy       angry\n",
       "\n",
       "[778 rows x 6 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1  #This is final collection of calculations and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        |           r     |\n",
      "        |           e     |\n",
      "        |   a   h   l     |\n",
      "        |   n   a   a     |\n",
      "        |   g   p   x   s |\n",
      "        |   r   p   e   a |\n",
      "        |   y   y   d   d |\n",
      "--------+-----------------+\n",
      "  angry |  <.>140  12  20 |\n",
      "  happy |   .<181> 13  12 |\n",
      "relaxed |   . 181  <9> 11 |\n",
      "    sad |   . 162  14 <23>|\n",
      "--------+-----------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lexicon Evaluation\n",
    "\n",
    "from nltk.metrics import precision, recall, accuracy, ConfusionMatrix\n",
    "\n",
    "preds = list(df1.iloc[:, 4])    #predicted class labels to feed into the confusion matrix\n",
    "actuals = list(df1.iloc[:, 5])  #actual class labels\n",
    "\n",
    "#print(list(preds))\n",
    "print(ConfusionMatrix(actuals, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DEPRECATED\n",
    "# Create train and test sets for each emotion\n",
    "\n",
    "random.shuffle(happy_lyrics)\n",
    "train_setHappy = happy_lyrics[:80]\n",
    "test_setHappy = happy_lyrics[81:]\n",
    "\n",
    "random.shuffle(angry_lyrics)\n",
    "train_setAngry = angry_lyrics[:80]\n",
    "test_setAngry = angry_lyrics[81:]\n",
    "\n",
    "random.shuffle(relaxed_lyrics)\n",
    "train_setRelaxed = relaxed_lyrics[:80]\n",
    "test_setRelaxed = relaxed_lyrics[81:]\n",
    "\n",
    "random.shuffle(sad_lyrics)\n",
    "train_setSad = sad_lyrics[:80]\n",
    "test_setSad = sad_lyrics[81:]\n",
    "\n",
    "training_docs = train_setHappy + train_setAngry + train_setRelaxed + train_setSad\n",
    "testing_docs = test_setHappy + test_setAngry + test_setRelaxed + test_setSad\n",
    "\n",
    "alldocs = training_docs + testing_docs\n",
    "#print(len(train_setHappy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
